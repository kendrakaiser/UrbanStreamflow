filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")  %>%
filter(crop %in% crops)
View(id_yeilds)
View(list_raw_id_ops)
View(id_ops_raw_data)
id_barley <- id_ops_raw_data %>%
filter(commodity_desc=="BARLEY")
View(id_barley)
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
library(dplyr)
# If you've never used your tidycensus API key in your R session, run this:
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
nass_key <- "B5240598-2A7D-38EE-BF8D-816A27BEF504" #QuickStats
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"
# commodity description of interest
my_commodity_desc<- "FARM OPERATIONS" #[AG LAND, INCL BUILDINGS - OPERATIONS WITH ASSET VALUE, MEASURED IN $ / ACRE; $ / OPERATION; $/ACRE; $]; [AG LAND, CROPLAND, PASTURED ONLY - ACRES] [Income, Net or Farm-related?]
# query start year
my_year <- "2000"
# state of interest
my_state <- "ID"
# final path string
path_id_farms <- paste0("api/api_GET/?key=", nass_key, "&commodity_desc=", my_commodity_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_farms <- GET(url = nass_url, path = path_id_farms)
char_raw_id_farms<- rawToChar(raw_id_farms$content)
# check size of object
nchar(char_raw_id_farms)
#turn into list
list_raw_id_farms<- fromJSON(char_raw_id_farms)
# apply rbind to each row of the list and convert to a data frame
id_farms_raw_data <- pmap_dfr(list_raw_id_farms, rbind)
colnames(id_farms_raw_data)[colnames(id_farms_raw_data)=="CV (%)"] <- "CV"
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY") %>%
filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
mutate(CV_trim = str_trim(CV)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, value_char =value_trim, unit_desc, CV_char = CV_trim) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
mutate(CV = suppressWarnings(as.numeric(CV_char))) %>%
# remove unnecessary columns
select(-value_char) %>%
select(-CV_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code)) %>%
#split up class description
separate(class_desc, c("class", "desc", "cat"), ',')
View(raw_id_farms)
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY")
View(id_county_agg)
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY") %>%
filter(unit_desc == "OPERATIONS")
unique(id_county_agg$domaincat_desc)
View(id_county_agg)
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
library(dplyr)
# If you've never used your tidycensus API key in your R session, run this:
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
nass_key <- "B5240598-2A7D-38EE-BF8D-816A27BEF504" #QuickStats
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"
# commodity description of interest
#my_commodity_desc<- "OPERATORS" #FARM OPERATIONS, [AG LAND, INCL BUILDINGS - OPERATIONS WITH ASSET VALUE, MEASURED IN $ / ACRE; $ / OPERATION; $/ACRE; $]; [AG LAND, CROPLAND, PASTURED ONLY - ACRES] [Income, Net or Farm-related?]
my_group_desc <-"CROPS"
# query start year
my_year <- "2013"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&sector_desc=", my_group_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
###--------------------------------------#
# Subset Data based on highest value crops
#####
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YEILD")
crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")  %>%
filter(crop %in% crops)
View(list_raw_id_ops)
my_year <- "2017"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&sector_desc=", my_group_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")  %>%
filter(crop %in% crops)
View(id_sales)
my_year <- "2018"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&sector_desc=", my_group_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
#crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")  %>%
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
#crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")
View(id_sales)
# query start year
my_year <- "2018"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&sector_desc=", my_group_desc, "&year=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
#crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")  %>%
#filter(crop %in% crops)
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
#crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")
View(id_sales)
View(id_ops_raw_data)
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(asd_desc,
agg_level_desc, year, short_desc, class_desc, domain_desc, value_char =value_trim, unit_desc, commodity_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)%>%
separate(short_desc, c("crop", 'info'), "- ")
View(id_sales)
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE")
View(id_sales)
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
filter(reference_period_desc == 'YEAR')
my_year <- "2010"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&sector_desc=", my_group_desc, "&year=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
###--------------------------------------#
# Subset Data based on highest value crops
#####
categories<-c("AREA HARVESTED", "PRICE RECEIVED", "YIELD")
#crops<-c("HOPS ", "PEACHES ", "PLUMS & PRUNES ", "PLUMS & PRUNES, ORGANIC ","PLUMS, ORGANIC ", "PEARS, ORGANIC ","PEACHES, ORGANIC ","GRAPES, ORGANIC ", "CHERRIES, SWEET ","MINT, PEPPERMINT, OIL ", "MINT, SPEARMINT, OIL " )
id_sales <- id_ops_raw_data %>%
#filter to specific data
#filter(statisticcat_desc=="SALES") %>%
#filter(unit_desc=="$") %>%
filter(statisticcat_desc %in% categories)%>%
filter(agg_level_desc=="STATE") %>%
filter(reference_period_desc == 'YEAR')
View(id_sales)
unique(id_sales$commodity_desc)
unique(id_ops_raw_data$commodity_desc)
tst<-unique(id_ops_raw_data$commodity_desc)
tst2<-unique(id_sales$commodity_desc)
library(dataRetrieval)
library(tidyverse)
setwd("~/Documents/GitRepos/UrbanStreamflow")
USGS_sites<- read_csv('USGSGages.csv')
siteInfo<-readNWISdata(sites= USGS_sites$Code, service="site")
write_csv(siteInfo, "siteInfo.csv")
start=as.Date("2019-01-16")
end= as.Date("2019-03-16")
pCode <- "00060"
flowdata <- readNWISuv(siteNumbers = siteInfo$site_no, parameterCd = pCode, startDate = start, endDate = end) %>% renameNWISColumns() %>% data.frame
flow<-merge(flowdata, USGS_sites, by.x="site_no", by.y="Code", all=TRUE)
Drains<-flow[flow$Cat == 'Drain',]
drainID<-unique(Drains$site_no)
plot(Drains$dateTime[Drains$site_no == drainID[1]], Drains$Flow_Inst[Drains$site_no == drainID[1]], type="l", col="blue", ylim=c(0, 80))
for (i in 2:3){
lines(Drains$dateTime[Drains$site_no == drainID[i]], Drains$Flow_Inst[Drains$site_no == drainID[i]])
}
plot(Drains$dateTime[Drains$site_no == drainID[4]], Drains$Flow_Inst[Drains$site_no == drainID[4]], type="l", col="blue") #Dixie Drain
Nat<-flow[flow$Cat == 'Natural',]
natID<-unique(Nat$site_no)
plot(Nat$dateTime[Nat$site_no == natID[1]], Nat$Flow_Inst[Nat$site_no == natID[1]], type="l", col="blue", ylim=c(0, 950))
lines(Nat$dateTime[Nat$site_no ==natID[2]], Nat$Flow_Inst[Nat$site_no == natID[2]])
lines(Nat$dateTime[Nat$site_no ==natID[3]], Nat$Flow_Inst[Nat$site_no == natID[3]], col = 'green')
plot(Nat$dateTime[Nat$site_no == natID[4]], Nat$Flow_Inst[Nat$site_no == natID[4]], type="l", col="blue")
View(USGS_sites)
Managed<-flow[flow$Cat == 'Managed',]
manID<-unique(Managed$site_no)
plot(Managed$dateTime[Managed$site_no == manID[1]], Managed$Flow_Inst[Managed$site_no == manID[1]], type="l", col="blue")
for (i in 2:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
View(Managed)
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue")
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(0, 950))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 1200))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 1600))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 2000))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 2500))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 2600))
for (i in 3:7){
lines(Managed$dateTime[Managed$site_no == manID[i]], Managed$Flow_Inst[Managed$site_no == manID[i]])
}
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 2600))
lines(Managed$dateTime[Managed$site_no == manID[3]], Managed$Flow_Inst[Managed$site_no == manID[3]], col='green')
lines(Managed$dateTime[Managed$site_no == manID[4]], Managed$Flow_Inst[Managed$site_no == manID[4]], col='orange')
lines(Managed$dateTime[Managed$site_no == manID[5]], Managed$Flow_Inst[Managed$site_no == manID[5]], col='red')
lines(Managed$dateTime[Managed$site_no == manID[6]], Managed$Flow_Inst[Managed$site_no == manID[6]], col='yellow')
lines(Managed$dateTime[Managed$site_no == manID[7]], Managed$Flow_Inst[Managed$site_no == manID[7]])
plot(Managed$dateTime[Managed$site_no == manID[4]], Managed$Flow_Inst[Managed$site_no == manID[4]], col='orange')
plot(Managed$dateTime[Managed$site_no == manID[4]], Managed$Flow_Inst[Managed$site_no == manID[4]], col='orange')
plot(Managed$dateTime[Managed$site_no == manID[4]], Managed$Flow_Inst[Managed$site_no == manID[4]], type='l', col='orange')
max(Managed$Flow_Inst[Managed$site_no == manID[4]])
manID[4]
max(Managed$Flow_Inst[Managed$site_no == manID[5]])
manID[5]
manID[2]
manID[3]
manID[6]
manID[7]
library(XML)
# pu: cumulative water year precip; px: observed daily totatl precip; ID: computed reservoir inflow
url_ark <- "daily_precip_ark.htm" #(10/01/1997 through 09/12/2018)
data_ark <- readHTMLTable(url_ark, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)# Read the HTML table
ark=data_ark[[1]] #convert to data frame
url_and <- "daily_precip_and.htm"# Assign URL - Anderson Ranch
data_and <- readHTMLTable(url_and, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
and=data_and[[1]]
url_luc <- "luc_daily.htm"#Lucky Peak
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
install.packages("XML")
library(XML)
# pu: cumulative water year precip; px: observed daily totatl precip; ID: computed reservoir inflow
url_ark <- "daily_precip_ark.htm" #arrowrock
data_ark <- readHTMLTable(url_ark, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)# Read the HTML table
ark=data_ark[[1]] #convert to data frame
url_and <- "daily_precip_and.htm"# Assign URL - Anderson Ranch
data_and <- readHTMLTable(url_and, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
and=data_and[[1]]
url_luc <- "luc_daily.htm"#Lucky Peak
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
View(data_and)
res<-data.frame("Date"= as.Date(and[,1]), "andP"=as.numeric(and$and_pp), "arkP" = as.numeric(ark$ark_pp), "in_computed_ark"=as.numeric(ark$ark_id), "lucQ" = as.numeric(luc$luc_qd), "in_computed_LUC"=as.numeric(luc$luc_id), "in_unreg_LUC"= as.numeric(luc$luc_qu))
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="black", ylim=c(200, 2600))
lines(res$Date, res$lucQ, col='blue')
plot(res$Date, res$lucQ, col='blue')
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="black", ylim=c(200, 3000))
lines(res$Date, res$lucQ, col='blue')
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 3000))
lines(Managed$dateTime[Managed$site_no == manID[3]], Managed$Flow_Inst[Managed$site_no == manID[3]], col='green')
lines(Managed$dateTime[Managed$site_no == manID[6]], Managed$Flow_Inst[Managed$site_no == manID[6]], col='orange')
lines(Managed$dateTime[Managed$site_no == manID[7]], Managed$Flow_Inst[Managed$site_no == manID[7]], col= 'red')
legend(1, 2250, legend=c("Below Arrowrock", "Below Lucky Peak", "Glenwood", "Caldwell", "Parma"),col=c("blue", "green", 'orange', 'red'), lty=1:2, cex=0.8)
plot(res$Date, res$lucQ, col='black', type='l')
plot(Managed$dateTime[Managed$site_no == manID[2]], Managed$Flow_Inst[Managed$site_no == manID[2]], type="l", col="blue", ylim=c(200, 3000))
lines(Managed$dateTime[Managed$site_no == manID[3]], Managed$Flow_Inst[Managed$site_no == manID[3]], col='green')
lines(Managed$dateTime[Managed$site_no == manID[6]], Managed$Flow_Inst[Managed$site_no == manID[6]], col='orange')
lines(Managed$dateTime[Managed$site_no == manID[7]], Managed$Flow_Inst[Managed$site_no == manID[7]], col= 'red')
legend(1, 2250, legend=c("Below Arrowrock", "Below Lucky Peak", "Glenwood", "Caldwell", "Parma"),col=c("blue", "green", 'orange', 'red'), lty=1:2, cex=0.8)
legend(1, 2250, legend=c("Below Arrowrock", "Glenwood", "Caldwell", "Parma"),col=c("blue", "green", 'orange', 'red'), lty=1:2, cex=0.8)
legend("topleft", legend=c("Below Arrowrock", "Glenwood", "Caldwell", "Parma"), col=c("blue", "green", 'orange', 'red'), lty=1:2, cex=0.8)
Nat<-flow[flow$Cat == 'Natural',]
natID<-unique(Nat$site_no)
plot(Nat$dateTime[Nat$site_no == natID[1]], Nat$Flow_Inst[Nat$site_no == natID[1]], type="l", col="blue", ylim=c(0, 950))
lines(Nat$dateTime[Nat$site_no ==natID[2]], Nat$Flow_Inst[Nat$site_no == natID[2]])
lines(Nat$dateTime[Nat$site_no ==natID[3]], Nat$Flow_Inst[Nat$site_no == natID[3]], col = 'green')
plot(Nat$dateTime[Nat$site_no == natID[4]], Nat$Flow_Inst[Nat$site_no == natID[4]], type="l", col="blue")
url_luc <- "daily_luc_spring.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
luc_spring<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucI"=as.numeric(luc$luc_id))
plot(luc_spring$Date, luc_spring$lucQ, type='l')
View(luc)
url_nyc<- "nyc_daily.htm"#new york canal
data_nyc<- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
nyc=data_nyc[[1]]
data_nyc<- readHTMLTable(url_nyc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
nyc=data_nyc[[1]]
luc_spring<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucI"=as.numeric(luc$luc_id), "nycQ"=as.numeric(nyc$bsei_qj))
nyc_spring<-data.frame("Date"= as.Date(nyc[,1]),"nycQ"=as.numeric(nyc$bsei_qj))
plot(nyc_spring$Date, nyc_spring$bsei_qj)
nyc_spring<-data.frame("Date"= as.Date(nyc[,1]),"nycQ"=as.numeric(nyc$bsei_qj), type='l')
plot(nyc_spring$Date, nyc_spring$bsei_qj, type='l')
plot(nyc_spring$Date, nyc_spring$nycQ, type='l')
View(nyc_spring)
View(nyc_spring)
View(luc_spring)
