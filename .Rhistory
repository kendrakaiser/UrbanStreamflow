# commodity description of interest
my_commodity_desc<- "OPERATORS"
# query start year
my_year <- "2000"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&commodity_desc=", my_commodity_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
install.packages(c("httr", "jsonlite", "tidycensus", "tidyverse", "purrr", "mapview", "dplyr"))
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
library(dplyr)
# If you've never used your tidycensus API key in your R session, run this:
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
nass_key <- "B5240598-2A7D-38EE-BF8D-816A27BEF504" #QuickStats
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"
# commodity description of interest
my_commodity_desc<- "OPERATORS" #FARM OPERATIONS, [AG LAND, INCL BUILDINGS - OPERATIONS WITH ASSET VALUE, MEASURED IN $ / ACRE; $ / OPERATION; $/ACRE; $]; [AG LAND, CROPLAND, PASTURED ONLY - ACRES] [Income, Net or Farm-related?]
# query start year
my_year <- "2000"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&commodity_desc=", my_commodity_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
###--------------------------------------#
# Subset Data
#####
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
All_cat<- unique(id_ops_raw_data$class_desc)
variables<-c("(ALL)", "(ALL), FEMALE")
id_operators <- id_ops_raw_data %>%
#filter to counties in southern Idaho
filter(asd_desc %in% regions) %>%
filter(agg_level_desc == "COUNTY") %>%
filter(class_desc %in% variables)  %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi, county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
head(id_operators)
age_var<-(All_cat[3:9])
ages <- id_ops_raw_data %>%
#filter to counties in southern Idaho
#filter(asd_desc %in% regions) %>%
filter(class_desc %in% age_var)  %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi, county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
library(tidycensus)
install.packages("tidycensus")
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
library(dplyr)
# If you've never used your tidycensus API key in your R session, run this:
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
nass_key <- "B5240598-2A7D-38EE-BF8D-816A27BEF504" #QuickStats
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"
# commodity description of interest
my_commodity_desc<- "FARM OPERATIONS" #[AG LAND, INCL BUILDINGS - OPERATIONS WITH ASSET VALUE, MEASURED IN $ / ACRE; $ / OPERATION; $/ACRE; $]; [AG LAND, CROPLAND, PASTURED ONLY - ACRES] [Income, Net or Farm-related?]
# query start year
my_year <- "2000"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_farms <- paste0("api/api_GET/?key=", nass_key, "&commodity_desc=", my_commodity_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_farms <- GET(url = nass_url, path = path_id_farms)
char_raw_id_farms<- rawToChar(raw_id_farms$content)
# check size of object
nchar(char_raw_id_farms)
#turn into list
list_raw_id_farms<- fromJSON(char_raw_id_farms)
# apply rbind to each row of the list and convert to a data frame
id_farms_raw_data <- pmap_dfr(list_raw_id_farms, rbind)
#####--------------------------------------#
# Subset Data to State Level Aggreegates
#####
id_state_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "STATE") %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char)
#####--------------------------------------#
# Subset Data to County Level Aggreegates
#####
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY") %>%
filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
install.packages("stringr", type="source")
library("stringr", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
View(list_raw_id_farms)
utils:::menuInstallPkgs(type="source")
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY") %>%
filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
#mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, Value, unit_desc) %>% #value_char =value_trim
# filter out entries with codes '(D)' and '(Z)'
#filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
#mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
#select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "COUNTY") %>%
filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
#mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, Value, unit_desc) %>% #value_char =value_trim
# filter out entries with codes '(D)' and '(Z)'
#filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
#mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
#select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
#mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
View(id_county_agg)
unique(id_county_agg$domain_desc)
unique(id_county_agg$domaincat_desc)
unique(id_county_agg$class_desc)
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
id_county_agg <- id_farms_raw_data %>%
filter(agg_level_desc == "STATE") %>%
filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
#mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi,county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, Value, unit_desc) %>% #value_char =value_trim
# filter out entries with codes '(D)' and '(Z)'
#filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
#mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
#select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
#mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
View(id_county_agg)
View(id_county_agg)
# Download and subset NASS AG Census Data
# Created following https://sheilasaia.rbind.io/post/2019-01-04-nass-api/
library(httr)
library(jsonlite)
library(tidycensus)
library(tidyverse)
library(purrr)
library(mapview)
library(dplyr)
# If you've never used your tidycensus API key in your R session, run this:
census_api_key("6fd2754dd1bdcc811b51c669667df2873b3bd56e")
nass_key <- "B5240598-2A7D-38EE-BF8D-816A27BEF504" #QuickStats
# NASS url
nass_url <- "http://quickstats.nass.usda.gov"
# commodity description of interest
my_commodity_desc<- "OPERATORS" #FARM OPERATIONS, [AG LAND, INCL BUILDINGS - OPERATIONS WITH ASSET VALUE, MEASURED IN $ / ACRE; $ / OPERATION; $/ACRE; $]; [AG LAND, CROPLAND, PASTURED ONLY - ACRES] [Income, Net or Farm-related?]
# query start year
my_year <- "2000"
# state of interest
my_state <- "ID"
###--------------------------------------#
# Download data and turn into dataframe
#####
# final path string
path_id_ops <- paste0("api/api_GET/?key=", nass_key, "&commodity_desc=", my_commodity_desc, "&year__GE=", my_year, "&state_alpha=", my_state)
#unpack JSON object
raw_id_ops <- GET(url = nass_url, path = path_id_ops)
char_raw_id_ops<- rawToChar(raw_id_ops$content)
# check size of object
nchar(char_raw_id_ops)
#turn into list
list_raw_id_ops<- fromJSON(char_raw_id_ops)
# apply rbind to each row of the list and convert to a data frame
id_ops_raw_data <- pmap_dfr(list_raw_id_ops, rbind)
###--------------------------------------#
# Subset Data to number of operators in each county, and age groups at state level
#####
regions <- c("EAST", "SOUTHWEST", "SOUTH CENTRAL")
All_cat<- unique(id_ops_raw_data$class_desc) #age categories
variables<-c("(ALL)", "(ALL), FEMALE", All_cat[3:9])
id_operators <- id_ops_raw_data %>%
#filter to specific data
#filter(class_desc %in% variables)  %>%
#filter(asd_desc %in% regions) %>%
# trim white space from ends (note: 'Value' is a character here, not a number)
mutate(value_trim = str_trim(Value)) %>%
# select only the columns we'll need
select(state_alpha, state_ansi, county_code, county_name, asd_desc,
agg_level_desc, year, class_desc, domain_desc, domaincat_desc, value_char =value_trim, unit_desc) %>%
# filter out entries with codes '(D)' and '(Z)'
filter(value_char != "(D)" & value_char != "(Z)") %>%
# remove commas from number values and convert to R numeric class
mutate(value = as.numeric(str_remove(value_char, ","))) %>%
# remove unnecessary columns
select(-value_char) %>%
# make a column with the county name and year (we'll need this for plotting)
mutate(county_year = paste0(str_to_lower(county_name), "_", year)) %>%
# make GEOID column to match up with county level spatial data (we'll need this for mapping)
mutate(GEOID = paste0(state_ansi, county_code))
ages<- id_operators %>%
filter( year == 2007) %>%
filter(class_desc %in% All_cat[3:9])%>%
select(-state_ansi, -county_name, -county_code, -asd_desc, -county_year, -GEOID)
All_cat[3:9]
install.packages("data.table")
install.packages("maxnet")
install.packages("xgboost")
library( dplyr )
rm(list=ls())
##### Create a social network of agents
# generate initial population
x <- 1:50
y <- 1:50
# number of iterations
numstep <- 50
numcell <- 2500
pop <- expand.grid(x, y)
View(pop)
names(pop) <- c("x", "y")
library(dataRetrieval)
library(tidyverse)
setwd("~/Documents/GitRepos/UrbanStreamflow")
library(XML)
url_nyc<- "nyc_daily.htm"#new york canal
data_nyc<- readHTMLTa
url_nyc<- "nyc_daily.htm"#new york canal
data_nyc<- readHTMLTable(url_nyc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
nyc=data_nyc[[1]]
nyc_spring<-data.frame("Date"= as.Date(nyc[,1]),"nycQ"=as.numeric(nyc$bsei_qj))
plot(nyc_spring$Date, nyc_spring$nycQ, type='l')
url_nyc<- "NYC_tenyear.htm"#new york canal
data_nyc<- readHTMLTable(url_nyc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
nyc=data_nyc[[1]]
nyc_spring<-data.frame("Date"= as.Date(nyc[,1]),"nycQ"=as.numeric(nyc$bsei_qj))
plot(nyc_spring$Date, nyc_spring$nycQ, type='l')
View(nyc_spring)
install.packages("openair")
library(openair)
install.packages("gfortran")
library(lubridate) # work with dates
library(dplyr)
nyc_spring$doy<-yday(nyc_spring$Date)
nyc_daily<-group_by(nyc_spring, doy)
class(nyc_daily)
nycQmean<-summarize(nyc_daily, mean(nycQ, na.rm=TRUE))
View(nycQmean)
nycQsd<-summarize(nyc_daily, sd(nycQ, na.rm=TRUE))
plot(nycQmean[,2], type='l')
plot(nycQmean$doy, nycQmean[,2], type='l')
plot(nycQmean$doy, nycQmean$`mean(nycQ, na.rm = TRUE)`, type='l')
nycQmean$sdl<- nycQmean$`mean(nycQ, na.rm = TRUE)` - nycQsd$`sd(nycQ, na.rm = TRUE)`
names(nycQmean)<- c("doy", "mean")
nycQmean<-summarize(nyc_daily, mean(nycQ, na.rm=TRUE))
nycQsd<-summarize(nyc_daily, sd(nycQ, na.rm=TRUE))
names(nycQmean)<- c("doy", "mean")
names(nycQsd)<- c("doy", "sd")
nycQmean$sdl<- nycQmean$mean - nycQsd$sd
nycQmean$sdu<- nycQmean + nycQsd$sd
nycQmean<-summarize(nyc_daily, mean(nycQ, na.rm=TRUE))
nycQsd<-summarize(nyc_daily, sd(nycQ, na.rm=TRUE))
names(nycQmean)<- c("doy", "mean")
names(nycQsd)<- c("doy", "sd")
nycQmean$sdl<- nycQmean$mean - nycQsd$sd
nycQmean$sdu<- nycQmean$mean + nycQsd$sd
plot(nycQmean$doy, nycQmean$mean, type='l')
lines(nycQmean$doy, nycQmean$sdl)
lines(nycQmean$doy, nycQmean$sdu)
nyc_spring$mean<-summarize(nyc_daily, mean(nycQ, ))
max(nycQmean$sdu)
plot(nycQmean$doy, nycQmean$mean, type='l', ylim= c(0, 2500))
lines(nycQmean$doy, nycQmean$sdl)
lines(nycQmean$doy, nycQmean$sdu)
View(nycQmean)
View(nyc_daily)
nycQmean$mo<- month(nyc_spring$Date[93:457])
nycQmean$mo<- month(nyc_spring$Date[93:458])
View(nycQmean)
url_luc <- "luc_daily.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
View(luc)
plot(luc$DateTime, luc$luc_qu, type='l', xlab="Date", ylab="Discharge (cfs)")
lines(luc$DateTime, luc$luc_id)
View(luc)
luc<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucI"=as.numeric(luc$luc_id))
url_luc <- "luc_daily.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
url_luc <- "luc_daily.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
luc<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucI"=as.numeric(luc$luc_id))
View(luc)
plot(luc$DateTime, luc$lucQ, type='l', xlab="Date", ylab="Discharge (cfs)")
lines(luc$DateTime, luc$lucI)
View(luc)
plot(luc$Date, luc$lucQ, type='l', xlab="Date", ylab="Discharge (cfs)")
lines(luc$Date, luc$lucI)
url_luc <- "luc_daily.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
View(luc)
lines(luc$Date, luc$lucI, col="blue")
luc<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucIn"=as.numeric(luc$luc_id), "luc_unreg"=as.numeric(luc$luc_qd))
plot(luc$Date, luc$lucQ, type='l', xlab="Date", ylab="Discharge (cfs)")
lines(luc$Date, luc$lucIn, col="blue")
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)")
lines(luc$Date, luc$lucQ, col="blue")
max(luc$lucIn)
max(luc$lucIn, na.rm = TRUE)
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)", ylim=c(0,16000))
lines(luc$Date, luc$lucQ, col="blue")
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)", ylim=c(0,16000))
lines(luc$Date, luc$luc_unreg, col="blue")
luc$lucQ[luc$lucQ <0]<-0
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)")#, ylim=c(0,16000))
luc$lucQ[luc$lucQ < 0]=0
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)")#, ylim=c(0,16000))
luc$lucQ[luc$lucQ < 0]
luc[luc$lucQ < 0]
which(luc$lucQ < 0])
which(luc$lucQ < 0)
which(luc$lucIn < 0)
luc$lucIn[id]=0
luc$lucIn[id]
luc$lucIn(id)
luc$lucIn[10]
luc$lucIn[which(luc$lucIn < 0)]=0
which(luc$lucIn < 0)
plot(luc$Date, luc$lucIn, type='l', xlab="Date", ylab="Discharge (cfs)")#, ylim=c(0,16000))
luc$doy<-yday(luc$Date)
luc_daily<-group_by(luc, doy)
lucQ<-summarize(luc_daily, mean(lucIn, na.rm=TRUE))
lucQsd<-summarize(luc_daily, sd(lucIn, na.rm=TRUE))
names(lucQ)<- c("doy", "mean")
names(lucQsd)<- c("doy", "sd")
lucQ$sdl<-lucQ$mean - lucQsd$sd
lucQ$sdu<- lucQ$mean + lucQsd$sd
max(lucQ$sdu)
plot(lucQ$doy, lucQ$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQ$doy,lucQ$sdl)
lines(lucQ$doy, lucQ$sdu)
lucQout<-summarize(luc_daily, mean(lucQ, na.rm=TRUE))
lucQsdout<-summarize(luc_daily, sd(lucQ, na.rm=TRUE))
names(lucQout)<- c("doy", "mean")
names(lucQsdout)<- c("doy", "sd")
lucQout$sdl<-lucQout$mean - lucQsdout$sd
lucQout$sdu<- lucQout$mean + lucQsdout$sd
plot(lucQout$doy, lucQout$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQout$doy,lucQout$sdl)
lines(lucQout$doy, lucQout$sdu)
plot(lucQ$doy, lucQ$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)", col='blue')
lines(lucQ$doy,lucQ$sdl, col='blue')
lines(lucQ$doy, lucQ$sdu, col='blue')
lines(lucQout$doy, lucQout$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQout$doy,lucQout$sdl)
lines(lucQout$doy, lucQout$sdu)
lucQur<-summarize(luc_daily, mean(luc_unreg, na.rm=TRUE))
lucQsdur<-summarize(luc_daily, sd(luc_unreg, na.rm=TRUE))
names(lucQur)<- c("doy", "mean")
names(lucQsdur)<- c("doy", "sd")
lucQur$sdl<-lucQur$mean - lucQsdur$sd
lucQur$sdu<- lucQur$mean + lucQsdur$sd
plot(lucQur$doy, lucQur$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQur$doy,lucQur$sdl)
lines(lucQur$doy, lucQur$sdu)
luc<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucIn"=as.numeric(luc$luc_id), "luc_unreg"=as.numeric(luc$luc_qu))
url_luc <- "luc_daily.htm"#Lucky Peak "luc_daily.htm"
data_luc <- readHTMLTable(url_luc, header=TRUE, as.data.frame = TRUE, stringsAsFactors=FALSE)
luc=data_luc[[1]]
luc<-data.frame("Date"= as.Date(luc[,1]), "lucQ"=as.numeric(luc$luc_qd), "lucIn"=as.numeric(luc$luc_id), "luc_unreg"=as.numeric(luc$luc_qu))
luc$lucIn[which(luc$lucIn < 0)]=0
luc$doy<-yday(luc$Date)
luc_daily<-group_by(luc, doy)
lucQ<-summarize(luc_daily, mean(lucIn, na.rm=TRUE))
lucQsd<-summarize(luc_daily, sd(lucIn, na.rm=TRUE))
names(lucQ)<- c("doy", "mean")
names(lucQsd)<- c("doy", "sd")
lucQ$sdl<-lucQ$mean - lucQsd$sd
lucQ$sdu<- lucQ$mean + lucQsd$sd
lucQout<-summarize(luc_daily, mean(lucQ, na.rm=TRUE))
lucQsdout<-summarize(luc_daily, sd(lucQ, na.rm=TRUE))
names(lucQout)<- c("doy", "mean")
names(lucQsdout)<- c("doy", "sd")
lucQout$sdl<-lucQout$mean - lucQsdout$sd
lucQout$sdu<- lucQout$mean + lucQsdout$sd
lucQur<-summarize(luc_daily, mean(luc_unreg, na.rm=TRUE))
lucQsdur<-summarize(luc_daily, sd(luc_unreg, na.rm=TRUE))
names(lucQur)<- c("doy", "mean")
names(lucQsdur)<- c("doy", "sd")
lucQur$sdl<-lucQur$mean - lucQsdur$sd
lucQur$sdu<- lucQur$mean + lucQsdur$sd
plot(lucQur$doy, lucQur$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQur$doy,lucQur$sdl)
lines(lucQur$doy, lucQur$sdu)
max(lucQur$sdu, na.rm = TRUE)
plot(lucQur$doy, lucQur$mean, type='l', ylim= c(0, 14000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQur$doy,lucQur$sdl)
lines(lucQur$doy, lucQur$sdu)
plot(lucQur$doy, lucQur$mean, type='l', ylim= c(0, 14000), xlab="Date", ylab="Discharge (cfs)", col='blue')
lines(lucQur$doy,lucQur$sdl, col='blue')
lines(lucQur$doy, lucQur$sdu, col='blue')
lines(lucQout$doy, lucQout$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)")
lines(lucQout$doy,lucQout$sdl)
lines(lucQout$doy, lucQout$sdu)
plot(lucQ$doy, lucQ$mean, type='l', ylim= c(0, 10000), xlab="Date", ylab="Discharge (cfs)", col='blue')
lines(lucQ$doy,lucQ$sdl, col='blue')
lines(lucQ$doy, lucQ$sdu, col='blue')
plot(lucQur$doy, lucQur$mean, type='l', ylim= c(0, 14000), xlab="Date", ylab="Discharge (cfs)", col='blue')
lines(lucQ$doy, lucQ$mean, type='l', col='green')
plot(luc$Date[93:458], lucQur$mean, type='l', ylim= c(0, 14000), xlab="Date", ylab="Discharge (cfs)", col='blue')
lines(luc$Date[93:458],lucQur$sdl, col='blue')
lines(luc$Date[93:458], lucQur$sdu, col='blue')
lines(luc$Date[93:458], lucQout$mean)
lines(luc$Date[93:458],lucQout$sdl)
lines(luc$Date[93:458], lucQout$sdu)
plot(luc$Date[93:458], nycQmean$mean, type='l', ylim= c(0, 2500), xlab="Date", ylab="Discharge (cfs)")
lines(luc$Date[93:458], nycQmean$sdl)
lines(luc$Date[93:458], nycQmean$sdu)
